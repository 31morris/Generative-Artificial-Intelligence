adam_beta1: 0.9
adam_beta2: 0.999
adam_epsilon: 1.0e-08
adam_weight_decay: 0.01
allow_tf32: false
alpha: 0.9
checkpoint_total_limit: 40
config_path: configs/base.yaml
dataloader_num_workers: 8
dataset_path: ./data/train.json
deepspeed: ./configs/zero2.json
gradient_accumulation_steps: 5
learning_rate: 0.0001
local_rank: 0
logging_dir: logs
lr_scheduler: constant
lr_warmup_steps: 500
max_grad_norm: 1.0
max_train_steps: 200000
mixed_precision: 'no'
num_train_epochs: 18182
output_dir: ./checkpoints
pretrained_model_name_or_path: google/flan-t5-base
report_to: tensorboard
resume_from_checkpoint: null
scale_lr: false
seed: null
set_grads_to_none: false
train_batch_size: 4
use_8bit_adam: true
